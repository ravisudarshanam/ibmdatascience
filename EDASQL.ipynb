{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Requirement already satisfied: psycopg2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (2.8.6)\nProject libraries has been successfully installed!\n"
                }
            ],
            "source": "# install for connection to postgres database (local)\n!pip install psycopg2\n\nimport csv\nimport psycopg2\nimport pandas as pd\n\n# install for connection to the database using DB2 (cloud)\n#!pip install sqlalchemy==1.3.9\n#!pip install ibm_db_sa\n#!pip install ipython-sql\nprint('Project libraries has been successfully installed!')"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Collecting ibm_db==3.1.0\n  Downloading ibm_db-3.1.0.tar.gz (797 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 797 kB 19.6 MB/s eta 0:00:01\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n\u001b[?25hCollecting ibm_db_sa==0.3.3\n  Downloading ibm_db_sa-0.3.3.tar.gz (24 kB)\nCollecting sqlalchemy>=0.7.3\n  Downloading SQLAlchemy-1.4.31-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.6 MB 53.2 MB/s eta 0:00:01\n\u001b[?25hCollecting greenlet!=0.4.17\n  Downloading greenlet-1.1.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (153 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 153 kB 61.5 MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: ibm-db, ibm-db-sa\n  Building wheel for ibm-db (PEP 517) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ibm-db: filename=ibm_db-3.1.0-cp39-cp39-linux_x86_64.whl size=267243 sha256=595db59ddc8d56b1bb5176751398654370f346b32db606385363c4ff57aadca4\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/0a/dd/10/4a9ad59949e39786d729813e4bce24ccf2263c6d60a62de2f2\n  Building wheel for ibm-db-sa (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ibm-db-sa: filename=ibm_db_sa-0.3.3-py3-none-any.whl size=27427 sha256=ef884bb504362925af08df87efb7163ca3fda2a97b6f312b939f94cae2875e47\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/8f/98/0c/930c68279890092297e12d4cc20e95613ddab15af6753d92bb\nSuccessfully built ibm-db ibm-db-sa\nInstalling collected packages: greenlet, sqlalchemy, ibm-db-sa, ibm-db\n  Attempting uninstall: greenlet\n    Found existing installation: greenlet 1.1.1\n    Uninstalling greenlet-1.1.1:\n      Successfully uninstalled greenlet-1.1.1\n  Attempting uninstall: sqlalchemy\n    Found existing installation: SQLAlchemy 1.4.27\n    Uninstalling SQLAlchemy-1.4.27:\n      Successfully uninstalled SQLAlchemy-1.4.27\n  Attempting uninstall: ibm-db-sa\n    Found existing installation: ibm-db-sa 0.3.7\n    Uninstalling ibm-db-sa-0.3.7:\n      Successfully uninstalled ibm-db-sa-0.3.7\n  Attempting uninstall: ibm-db\n    Found existing installation: ibm-db 3.1.0\n    Uninstalling ibm-db-3.1.0:\n      Successfully uninstalled ibm-db-3.1.0\nSuccessfully installed greenlet-1.1.2 ibm-db-3.1.0 ibm-db-sa-0.3.3 sqlalchemy-1.4.31\nFound existing installation: SQLAlchemy 1.4.31\nUninstalling SQLAlchemy-1.4.31:\n  Successfully uninstalled SQLAlchemy-1.4.31\nCollecting sqlalchemy==1.3.24\n  Downloading SQLAlchemy-1.3.24-cp39-cp39-manylinux2010_x86_64.whl (1.3 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.3 MB 24.3 MB/s eta 0:00:01\n\u001b[?25hInstalling collected packages: sqlalchemy\nSuccessfully installed sqlalchemy-1.3.24\nCollecting ipython-sql\n  Downloading ipython_sql-0.4.0-py3-none-any.whl (19 kB)\nRequirement already satisfied: ipython-genutils>=0.1.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython-sql) (0.2.0)\nRequirement already satisfied: six in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython-sql) (1.15.0)\nRequirement already satisfied: sqlalchemy>=0.6.7 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython-sql) (1.3.24)\nCollecting prettytable<1\n  Downloading prettytable-0.7.2.zip (28 kB)\nCollecting sqlparse\n  Downloading sqlparse-0.4.2-py3-none-any.whl (42 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 42 kB 1.8 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: ipython>=1.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython-sql) (7.29.0)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (4.8.0)\nRequirement already satisfied: matplotlib-inline in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (0.1.2)\nRequirement already satisfied: pygments in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (2.10.0)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (0.18.0)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (3.0.20)\nRequirement already satisfied: backcall in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (0.2.0)\nRequirement already satisfied: setuptools>=18.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (58.0.4)\nRequirement already satisfied: pickleshare in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (0.7.5)\nRequirement already satisfied: traitlets>=4.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (5.1.1)\nRequirement already satisfied: decorator in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (5.1.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from jedi>=0.16->ipython>=1.0->ipython-sql) (0.8.3)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pexpect>4.3->ipython>=1.0->ipython-sql) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=1.0->ipython-sql) (0.2.5)\nBuilding wheels for collected packages: prettytable\n  Building wheel for prettytable (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for prettytable: filename=prettytable-0.7.2-py3-none-any.whl size=13714 sha256=ecd01ddc19a965b27cfa14e80c78a33ca0de0674672555613f672c69635c534d\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/75/f7/28/77a076f1fa8cbeda61aca712815d04d7a32435f04a26a2dd7b\nSuccessfully built prettytable\nInstalling collected packages: sqlparse, prettytable, ipython-sql\nSuccessfully installed ipython-sql-0.4.0 prettytable-0.7.2 sqlparse-0.4.2\n"
                }
            ],
            "source": "# These libraries are pre-installed in SN Labs. If running in another environment please uncomment lines below to install them:\n!pip install --force-reinstall ibm_db==3.1.0 ibm_db_sa==0.3.3\n# Ensure we don't load_ext with sqlalchemy>=1.4 (incompadible)\n!pip uninstall sqlalchemy==1.4 -y && pip install sqlalchemy==1.3.24\n!pip install ipython-sql"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": "import ibm_db"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": "dsn_hostname = \"b70af05b-76e4-4bca-a1f5-23dbb4c6a74e.c1ogj3sd0tgtu0lqde00.databases.appdomain.cloud\" # e.g.: \"54a2f15b-5c0f-46df-8954-7e38e612c2bd.c1ogj3sd0tgtu0lqde00.databases.appdomain.cloud\"\ndsn_uid = \"tvm01872\"        # e.g. \"abc12345\"\ndsn_pwd = \"kgzqXRMHNlAom7ha\"      # e.g. \"7dBZ3wWt9XN6$o0J\"\ndsn_driver = \"{IBM DB2 ODBC DRIVER}\"\ndsn_database = \"BLUDB\"            # e.g. \"BLUDB\"\ndsn_port = \"32716\"                # e.g. \"32733\" \ndsn_protocol = \"TCPIP\"            # i.e. \"TCPIP\"\ndsn_security = \"SSL\"              #i.e. \"SSL\""
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "DRIVER={IBM DB2 ODBC DRIVER};DATABASE=BLUDB;HOSTNAME=b70af05b-76e4-4bca-a1f5-23dbb4c6a74e.c1ogj3sd0tgtu0lqde00.databases.appdomain.cloud;PORT=32716;PROTOCOL=TCPIP;UID=tvm01872;PWD=kgzqXRMHNlAom7ha;SECURITY=SSL;\n"
                }
            ],
            "source": "dsn = (\n    \"DRIVER={0};\"\n    \"DATABASE={1};\"\n    \"HOSTNAME={2};\"\n    \"PORT={3};\"\n    \"PROTOCOL={4};\"\n    \"UID={5};\"\n    \"PWD={6};\"\n    \"SECURITY={7};\").format(dsn_driver, dsn_database, dsn_hostname, dsn_port, dsn_protocol, dsn_uid, dsn_pwd,dsn_security)\n\n#print the connection string to check correct values are specified\nprint(dsn)"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Connected to database:  BLUDB as user:  tvm01872 on host:  b70af05b-76e4-4bca-a1f5-23dbb4c6a74e.c1ogj3sd0tgtu0lqde00.databases.appdomain.cloud\n"
                }
            ],
            "source": "try:\n    conn = ibm_db.connect(dsn, \"\", \"\")\n    print (\"Connected to database: \", dsn_database, \"as user: \", dsn_uid, \"on host: \", dsn_hostname)\n\nexcept:\n    print (\"Unable to connect: \", ibm_db.conn_errormsg() )"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "DBMS_NAME:  DB2/LINUXX8664\nDBMS_VER:   11.05.0600\nDB_NAME:    BLUDB\n"
                }
            ],
            "source": "server = ibm_db.server_info(conn)\n\nprint (\"DBMS_NAME: \", server.DBMS_NAME)\nprint (\"DBMS_VER:  \", server.DBMS_VER)\nprint (\"DB_NAME:   \", server.DB_NAME)"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "DRIVER_NAME:           libdb2.a\nDRIVER_VER:            11.05.0600\nDATA_SOURCE_NAME:      BLUDB\nDRIVER_ODBC_VER:       03.51\nODBC_VER:              03.01.0000\nODBC_SQL_CONFORMANCE:  EXTENDED\nAPPL_CODEPAGE:         1208\nCONN_CODEPAGE:         1208\n"
                }
            ],
            "source": "client = ibm_db.client_info(conn)\n\nprint (\"DRIVER_NAME:          \", client.DRIVER_NAME) \nprint (\"DRIVER_VER:           \", client.DRIVER_VER)\nprint (\"DATA_SOURCE_NAME:     \", client.DATA_SOURCE_NAME)\nprint (\"DRIVER_ODBC_VER:      \", client.DRIVER_ODBC_VER)\nprint (\"ODBC_VER:             \", client.ODBC_VER)\nprint (\"ODBC_SQL_CONFORMANCE: \", client.ODBC_SQL_CONFORMANCE)\nprint (\"APPL_CODEPAGE:        \", client.APPL_CODEPAGE)\nprint (\"CONN_CODEPAGE:        \", client.CONN_CODEPAGE)"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": "%load_ext sql"
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Connection info needed in SQLAlchemy format, example:\n               postgresql://username:password@hostname/dbname\n               or an existing connection: dict_keys([])\nCan't load plugin: sqlalchemy.dialects:ibm_db_sa\nConnection info needed in SQLAlchemy format, example:\n               postgresql://username:password@hostname/dbname\n               or an existing connection: dict_keys([])\n"
                }
            ],
            "source": "%sql ibm_db_sa://tvm01872:kgzqXRMHNlAom7ha@b70af05b-76e4-4bca-a1f5-23dbb4c6a74e.c1ogj3sd0tgtu0lqde00.databases.appdomain.cloud:32716/BLUDB"
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Connection info needed in SQLAlchemy format, example:\n               postgresql://username:password@hostname/dbname\n               or an existing connection: dict_keys([])\nCan't load plugin: sqlalchemy.dialects:ibm_db_sa\nConnection info needed in SQLAlchemy format, example:\n               postgresql://username:password@hostname/dbname\n               or an existing connection: dict_keys([])\n"
                }
            ],
            "source": "%sql ibm_db_sa://"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Environment variable $DATABASE_URL not set, and no connect string given.\nConnection info needed in SQLAlchemy format, example:\n               postgresql://username:password@hostname/dbname\n               or an existing connection: dict_keys([])\n"
                }
            ],
            "source": "%%sql \nuses TVM01872;"
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": "# function to read from database\ndef read(conn, read_):\n    print('Read')\n    cursor = conn.cursor()\n    cursor.execute(read_)\n    for row in cursor:\n        print(f'row = {row}')\n    print()\n    \n# function to create in postgre database     \ndef create(conn, create_):\n    cursor = conn.cursor() # create cursor object\n    cursor.execute(create_) # execute query\n    conn.commit() # commit query to database\n    print('Table have been created successfull!!!')\n    #read(conn)\n    \n# function to insert in postgre database     \ndef insert(conn, insert_):\n    cursor = conn.cursor()\n    cursor.execute(insert_)\n    conn.commit()\n    print('Records have been successfully inserted!!!')\n    #read(conn)\n    \n# function to update table\ndef update(conn, update_):\n    print('Update')\n    cursor = conn.cursor()\n    cursor.execute(update_)\n    conn.commit()\n    #read(conn)\n    \n# function to delete in postgre database\ndef delete(conn, delete_):\n    print('Delete')\n    cursor = conn.cursor()\n    cursor.execute(delete_)\n    conn.commit()\n    #read(conn)\n\n# close the cursor and connection to the server \ndef close():\n    cursor.close()\n    conn.close()   \n    \n# function to create pandas dataframe\ndef create_pandas_df(sql_query, database=conn):\n    table = pd.read_sql_query(sql_query, database)\n    return table"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Create table in OracleSQL database"
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Collecting sqlalchemy==1.3.9\n  Downloading SQLAlchemy-1.3.9.tar.gz (6.0 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6.0 MB 12.7 MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: sqlalchemy\n  Building wheel for sqlalchemy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sqlalchemy: filename=SQLAlchemy-1.3.9-cp39-cp39-linux_x86_64.whl size=1159949 sha256=a8e73dbc3618f3c1e79800afd049eb8780cecee6a83f7018e9eeabfa0288cf6d\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/5b/43/0d/de1699809f9e6aaa54a97275298fa07075cb19acc557b18955\nSuccessfully built sqlalchemy\nInstalling collected packages: sqlalchemy\n  Attempting uninstall: sqlalchemy\n    Found existing installation: SQLAlchemy 1.3.24\n    Uninstalling SQLAlchemy-1.3.24:\n      Successfully uninstalled SQLAlchemy-1.3.24\nSuccessfully installed sqlalchemy-1.3.9\nRequirement already satisfied: ibm_db_sa in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (0.3.3)\nRequirement already satisfied: sqlalchemy>=0.7.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_db_sa) (1.3.9)\nRequirement already satisfied: ipython-sql in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (0.4.0)\nRequirement already satisfied: prettytable<1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython-sql) (0.7.2)\nRequirement already satisfied: sqlalchemy>=0.6.7 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython-sql) (1.3.9)\nRequirement already satisfied: ipython>=1.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython-sql) (7.29.0)\nRequirement already satisfied: sqlparse in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython-sql) (0.4.2)\nRequirement already satisfied: six in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython-sql) (1.15.0)\nRequirement already satisfied: ipython-genutils>=0.1.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython-sql) (0.2.0)\nRequirement already satisfied: pygments in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (2.10.0)\nRequirement already satisfied: traitlets>=4.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (5.1.1)\nRequirement already satisfied: backcall in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (0.2.0)\nRequirement already satisfied: decorator in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (5.1.0)\nRequirement already satisfied: setuptools>=18.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (58.0.4)\nRequirement already satisfied: pickleshare in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (3.0.20)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (0.18.0)\nRequirement already satisfied: matplotlib-inline in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (0.1.2)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (4.8.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from jedi>=0.16->ipython>=1.0->ipython-sql) (0.8.3)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pexpect>4.3->ipython>=1.0->ipython-sql) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=1.0->ipython-sql) (0.2.5)\n"
                }
            ],
            "source": "!pip install sqlalchemy==1.3.9\n!pip install ibm_db_sa\n!pip install ipython-sql"
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Project libraries has been successfully installed!\n"
                }
            ],
            "source": "print('Project libraries has been successfully installed!')"
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "The sql extension is already loaded. To reload it, use:\n  %reload_ext sql\n"
                }
            ],
            "source": "%load_ext sql"
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Connection info needed in SQLAlchemy format, example:\n               postgresql://username:password@hostname/dbname\n               or an existing connection: dict_keys([])\nCan't load plugin: sqlalchemy.dialects:ibm_db_sa\nConnection info needed in SQLAlchemy format, example:\n               postgresql://username:password@hostname/dbname\n               or an existing connection: dict_keys([])\n"
                }
            ],
            "source": "%sql ibm_db_sa://"
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Connection info needed in SQLAlchemy format, example:\n               postgresql://username:password@hostname/dbname\n               or an existing connection: dict_keys([])\ninvalid literal for int() with base 10: 'my-port'\nConnection info needed in SQLAlchemy format, example:\n               postgresql://username:password@hostname/dbname\n               or an existing connection: dict_keys([])\n"
                }
            ],
            "source": "%sql ibm_db_sa://my-username:my-password\\@my-hostname:my-port/my-db-name"
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Connection info needed in SQLAlchemy format, example:\n               postgresql://username:password@hostname/dbname\n               or an existing connection: dict_keys([])\ninvalid literal for int() with base 10: 'my-port'\nConnection info needed in SQLAlchemy format, example:\n               postgresql://username:password@hostname/dbname\n               or an existing connection: dict_keys([])\n"
                }
            ],
            "source": "%sql ibm_db_sa://my-username:my-password\\@my-hostname:my-port/my-db-name?security=SSL"
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Connection info needed in SQLAlchemy format, example:\n               postgresql://username:password@hostname/dbname\n               or an existing connection: dict_keys([])\nCan't load plugin: sqlalchemy.dialects:ibm_db_sa\nConnection info needed in SQLAlchemy format, example:\n               postgresql://username:password@hostname/dbname\n               or an existing connection: dict_keys([])\n"
                }
            ],
            "source": "%sql ibm_db_sa://tvm01872:kgzqXRMHNlAom7ha@b70af05b-76e4-4bca-a1f5-23dbb4c6a74e.c1ogj3sd0tgtu0lqde00.databases.appdomain.cloud:32716/BLUDB?security=SSL"
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Connection info needed in SQLAlchemy format, example:\n               postgresql://username:password@hostname/dbname\n               or an existing connection: dict_keys([])\nCan't load plugin: sqlalchemy.dialects:ibm_db_sa\nConnection info needed in SQLAlchemy format, example:\n               postgresql://username:password@hostname/dbname\n               or an existing connection: dict_keys([])\n"
                }
            ],
            "source": "%sql ibm_db_sa://"
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [
                {
                    "ename": "OperationalError",
                    "evalue": "could not translate host name \"b70af05b-76e4-4bca-a1f5-23dbb4c6a74e.c1ogj3sd0tgtu0lqde00.databases.appdomain.cloud:32716\" to address: Name or service not known\n",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
                        "\u001b[0;32m/tmp/wsuser/ipykernel_155/203011380.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create connection to postgreSQL database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m conn = psycopg2.connect(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mhost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'b70af05b-76e4-4bca-a1f5-23dbb4c6a74e.c1ogj3sd0tgtu0lqde00.databases.appdomain.cloud:32716'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdatabase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'BLUDB'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0muser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tvm01872'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/psycopg2/__init__.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0mdsn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dsn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection_factory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconnection_factory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwasync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcursor_factory\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcursor_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mOperationalError\u001b[0m: could not translate host name \"b70af05b-76e4-4bca-a1f5-23dbb4c6a74e.c1ogj3sd0tgtu0lqde00.databases.appdomain.cloud:32716\" to address: Name or service not known\n"
                    ]
                }
            ],
            "source": "# create connection to postgreSQL database\nconn = psycopg2.connect(\n    host = 'b70af05b-76e4-4bca-a1f5-23dbb4c6a74e.c1ogj3sd0tgtu0lqde00.databases.appdomain.cloud:32716',\n    database = 'BLUDB', \n    user = 'tvm01872', \n    password = 'kgzqXRMHNlAom7ha',  \n    port = '32716')\nprint('Connection to database is successfully')"
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Requirement already satisfied: psycopg2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (2.8.6)\r\n"
                }
            ],
            "source": "!pip install psycopg2"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# create table SpaceX\ncreate_ = '''\n            DROP TABLE IF EXISTS SpaceX;\n            CREATE TABLE SpaceX\n                (\n                    Date DATE NULL,\n                    Time TIME NULL,\n                    BoosterVersion VARCHAR(50) NULL,\n                    LaunchSite VARCHAR(50) NULL,\n                    Payload VARCHAR(100) NULL,\n                    PayloadMassKG INT NULL,\n                    Orbit VARCHAR(50) NULL,\n                    Customer VARCHAR(100) NULL,\n                    MissionOutcome VARCHAR(50) NULL,\n                    LandingOutcome VARCHAR(100) NULL\n                );\n            '''\ncreate(conn, create_)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# loading the csv file\ncursor = conn.cursor()\nwith open('Spacex.csv', 'r') as f:\n    reader = csv.reader(f)\n    next(reader) # Skip the header row.\n    for row in reader:\n        cursor.execute(\n        \"INSERT INTO SpaceX VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\",\n        row\n    )\nconn.commit()\nprint('CSV file inserted into database successfully!!!')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# read to see that data has been uploaded in database\nread_ = '''\n        SELECT *\n        FROM   SpaceX\n        LIMIT 10\n        '''\nread(conn, read_)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# output postgre query in pandas dataframe\nspacex = create_pandas_df(read_, database=conn)\nspacex.head(10)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "task_1 = '''\n        SELECT DISTINCT LaunchSite \n        FROM SpaceX\n'''\ncreate_pandas_df(task_1, database=conn)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "task_2 = '''\n        SELECT *\n        FROM SpaceX\n        WHERE LaunchSite LIKE 'CCA%'\n        LIMIT 5\n        '''\ncreate_pandas_df(task_2, database=conn)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "task_3 = '''\n        SELECT SUM(PayloadMassKG) AS Total_PayloadMass\n        FROM SpaceX\n        WHERE Customer LIKE 'NASA (CRS)'\n        '''\ncreate_pandas_df(task_3, database=conn)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "task_4 = '''\n        SELECT AVG(PayloadMassKG) AS Avg_PayloadMass\n        FROM SpaceX\n        WHERE BoosterVersion = 'F9 v1.1'\n        '''\ncreate_pandas_df(task_4, database=conn)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "task_5 = '''\n        SELECT MIN(Date) AS FirstSuccessfull_landing_date\n        FROM SpaceX\n        WHERE LandingOutcome LIKE 'Success (ground pad)'\n        '''\ncreate_pandas_df(task_5, database=conn)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "task_6 = '''\n        SELECT BoosterVersion\n        FROM SpaceX\n        WHERE LandingOutcome = 'Success (drone ship)'\n            AND PayloadMassKG > 4000 \n            AND PayloadMassKG < 6000\n        '''\ncreate_pandas_df(task_6, database=conn)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "task_7a = '''\n        SELECT COUNT(MissionOutcome) AS SuccessOutcome\n        FROM SpaceX\n        WHERE MissionOutcome LIKE 'Success%'\n        '''\n\ntask_7b = '''\n        SELECT COUNT(MissionOutcome) AS FailureOutcome\n        FROM SpaceX\n        WHERE MissionOutcome LIKE 'Failure%'\n        '''\nprint('The total number of successful mission outcome is:')\ndisplay(create_pandas_df(task_7a, database=conn))\nprint()\nprint('The total number of failed mission outcome is:')\ncreate_pandas_df(task_7b, database=conn)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "task_8 = '''\n        SELECT BoosterVersion, PayloadMassKG\n        FROM SpaceX\n        WHERE PayloadMassKG = (\n                                SELECT MAX(PayloadMassKG)\n                                FROM SpaceX\n                                )\n        ORDER BY BoosterVersion\n        '''\ncreate_pandas_df(task_8, database=conn)"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.9",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}